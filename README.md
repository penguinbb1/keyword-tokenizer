# ğŸ·ï¸ Multilingual E-commerce Keyword Tokenizer

å¤šè¯­è¨€ç”µå•†å…³é”®è¯åˆ†è¯ä¸è¯­ä¹‰æ ‡æ³¨ç³»ç»Ÿ

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹

- ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šä¸­æ–‡ã€æ—¥è¯­ã€è‹±è¯­ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­
- ğŸ”€ **æ··åˆè¯­è¨€å¤„ç†**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶åˆ†åˆ«å¤„ç† `Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º 26.5cm`
- ğŸ·ï¸ **è¯­ä¹‰æ ‡æ³¨**ï¼šå“ç‰Œè¯ã€å•†å“è¯ã€äººç¾¤è¯ã€åœºæ™¯è¯ã€é¢œè‰²è¯ã€å°ºå¯¸è¯ã€å–ç‚¹è¯ã€å±æ€§è¯
- ğŸ“Š **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šæ¯ä¸ªæ ‡æ³¨é™„å¸¦å¯ä¿¡åº¦åˆ†æ•°
- ğŸ¤– **AI å¢å¼º**ï¼šå¯é€‰çš„ Claude API è¡¥å……æ ‡æ³¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/keyword-tokenizer.git
cd keyword-tokenizer

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…æ—¥è¯­åˆ†è¯å™¨ï¼ˆå¯é€‰ï¼‰
pip install sudachipy sudachidict_core
```

### é…ç½®

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡ç¤ºä¾‹
cp .env.example .env

# ç¼–è¾‘ .envï¼Œé…ç½® API Keyï¼ˆå¯é€‰ï¼Œç”¨äº AI å¢å¼ºï¼‰
# ANTHROPIC_API_KEY=your-api-key-here
```

### ä½¿ç”¨

#### å‘½ä»¤è¡Œæµ‹è¯•

```bash
# å•æ¡æµ‹è¯•
python3 scripts/test_v2.py

# æ‰¹é‡æµ‹è¯•ï¼ˆä¸ä½¿ç”¨ AIï¼‰
python3 scripts/batch_test_v2.py keywords.csv -o results.json --no-ai

# æ‰¹é‡æµ‹è¯•ï¼ˆä½¿ç”¨ AI å¢å¼ºï¼‰
python3 scripts/batch_test_v2.py keywords.csv -o results.json
```

#### API æœåŠ¡

```bash
# å¯åŠ¨æœåŠ¡
python3 run.py

# è°ƒç”¨æ¥å£
curl -X POST "http://localhost:8000/api/tokenize" \
  -H "Content-Type: application/json" \
  -d '{"keyword": "Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º ãƒ¡ãƒ³ã‚º"}'
```

#### Python ä»£ç 

```python
import asyncio
from pathlib import Path
from services.dictionary_manager import DictionaryManager
from core.enhanced_pipeline import EnhancedPipeline

# åˆå§‹åŒ–
dict_manager = DictionaryManager(Path("dictionaries"))
dict_manager.load_all()
pipeline = EnhancedPipeline(dict_manager, enable_ai=False)

# å¤„ç†å…³é”®è¯
async def main():
    result = await pipeline.process("Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º ãƒ¡ãƒ³ã‚º 26.5cm")
    print(result)

asyncio.run(main())
```

## ğŸ“– è¾“å‡ºç¤ºä¾‹

```json
{
  "original_keyword": "Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º ãƒ¡ãƒ³ã‚º 26.5cm",
  "tokens": ["Nike", "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º", "ãƒ¡ãƒ³ã‚º", "26.5cm"],
  "tagged_tokens": [
    {"token": "Nike", "tag": "å“ç‰Œè¯", "confidence": 0.95},
    {"token": "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º", "tag": "å•†å“è¯", "confidence": 0.90},
    {"token": "ãƒ¡ãƒ³ã‚º", "tag": "äººç¾¤è¯", "confidence": 0.90},
    {"token": "26.5cm", "tag": "å°ºå¯¸è¯", "confidence": 0.95}
  ],
  "tag_summary": {
    "å“ç‰Œè¯": ["Nike"],
    "å•†å“è¯": ["ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º"],
    "äººç¾¤è¯": ["ãƒ¡ãƒ³ã‚º"],
    "å°ºå¯¸è¯": ["26.5cm"]
  }
}
```

## ğŸ·ï¸ æ ‡ç­¾ç±»å‹

| æ ‡ç­¾ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| å“ç‰Œè¯ | å“ç‰Œåç§° | Nike, Sony, ãƒŠã‚¤ã‚­ |
| å•†å“è¯ | å•†å“å“ç±» | leggings, ã‚·ãƒ¥ãƒ¼ã‚º, èƒŒåŒ… |
| äººç¾¤è¯ | ç›®æ ‡äººç¾¤ | damen, ãƒ¡ãƒ³ã‚º, kids |
| åœºæ™¯è¯ | ä½¿ç”¨åœºæ™¯ | running, ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ |
| é¢œè‰²è¯ | é¢œè‰² | schwarz, é»’, blue |
| å°ºå¯¸è¯ | å°ºå¯¸è§„æ ¼ | 26.5cm, XL, 32GB |
| å–ç‚¹è¯ | äº§å“ç‰¹æ€§ | waterproof, è»½é‡ |
| å±æ€§è¯ | å…¶ä»–å±æ€§ | with, fÃ¼r, long |

## ğŸ“ é¡¹ç›®ç»“æ„

```
keyword-tokenizer/
â”œâ”€â”€ api/                    # API æœåŠ¡
â”œâ”€â”€ config/                 # é…ç½®ç®¡ç†
â”œâ”€â”€ core/                   # æ ¸å¿ƒå¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ enhanced_pipeline.py    # ä¸»å¤„ç†æµæ°´çº¿
â”‚   â”œâ”€â”€ enhanced_tagger.py      # æ ‡ç­¾æ ‡æ³¨å™¨
â”‚   â”œâ”€â”€ phrase_merger.py        # çŸ­è¯­åˆå¹¶å™¨
â”‚   â”œâ”€â”€ script_segmenter.py     # è„šæœ¬åˆ†æ®µ
â”‚   â”œâ”€â”€ japanese_compound_merger.py  # æ—¥è¯­å¤åˆè¯
â”‚   â”œâ”€â”€ spanish_normalizer.py   # è¥¿ç­ç‰™è¯­å½’ä¸€åŒ–
â”‚   â””â”€â”€ tokenizers/             # åˆ†è¯å™¨
â”œâ”€â”€ services/               # æœåŠ¡å±‚
â”‚   â”œâ”€â”€ dictionary_manager.py   # è¯å…¸ç®¡ç†
â”‚   â””â”€â”€ ai_enhancer_v2.py       # AI å¢å¼º
â”œâ”€â”€ dictionaries/           # è¯å…¸æ•°æ®ï¼ˆ1,700+ è¯æ¡ï¼‰
â”œâ”€â”€ dict_expansion/         # è¯å…¸æ‰©å……å·¥å…·
â”œâ”€â”€ scripts/                # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ batch_test_v2.py        # æ‰¹é‡æµ‹è¯•
â”‚   â”œâ”€â”€ import_ai_tags.py       # å¯¼å…¥ AI æ ‡æ³¨
â”‚   â””â”€â”€ import_google_taxonomy.py  # å¯¼å…¥ Google å•†å“åˆ†ç±»
â””â”€â”€ docs/                   # æ–‡æ¡£
```

## ğŸ“š è¯å…¸ç®¡ç†

### å½“å‰è¯å…¸è§„æ¨¡

| è¯å…¸ | è¯æ¡æ•° | è¯´æ˜ |
|------|--------|------|
| products | 800+ | å•†å“è¯ï¼ˆå¤šè¯­è¨€ï¼‰ |
| attributes | 350+ | å±æ€§è¯ |
| scenarios | 145 | åœºæ™¯è¯ |
| brands | 110+ | å“ç‰Œè¯ |
| features | 83 | å–ç‚¹è¯ |
| audiences | 81 | äººç¾¤è¯ |
| colors | 68 | é¢œè‰²è¯ |
| çŸ­è¯­è¯å…¸ | 263 | å›ºå®šæ­é…ï¼ˆå†…ç½®ï¼‰ |

### è¯å…¸æ ¼å¼

```json
{
  "name": "å•†å“è¯å…¸",
  "entries": [
    {"word": "leggings", "confidence": 0.95},
    {"word": "ã‚·ãƒ¥ãƒ¼ã‚º", "confidence": 0.95}
  ]
}
```

### æ‰©å……è¯å…¸

```bash
# æ–¹å¼ä¸€ï¼šä½¿ç”¨è¯å…¸æ‰©å……æ¨¡å—
python3 dict_expansion/apply_expansion.py --dry-run  # é¢„è§ˆ
python3 dict_expansion/apply_expansion.py            # å®é™…å¯¼å…¥

# æ–¹å¼äºŒï¼šå¯¼å…¥ Google Product Taxonomy
python3 scripts/import_google_taxonomy.py --lang en --dry-run  # é¢„è§ˆ
python3 scripts/import_google_taxonomy.py --lang en            # å¯¼å…¥è‹±è¯­
python3 scripts/import_google_taxonomy.py --lang de            # å¯¼å…¥å¾·è¯­

# æ–¹å¼ä¸‰ï¼šå¯¼å…¥ AI æ ‡æ³¨ç»“æœ
python3 scripts/import_ai_tags.py results.json --dry-run
python3 scripts/import_ai_tags.py results.json
```

## âš™ï¸ é…ç½®é€‰é¡¹

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|----------|------|--------|
| `ANTHROPIC_API_KEY` | Claude API Keyï¼ˆAI å¢å¼ºç”¨ï¼‰ | - |
| `API_HOST` | API æœåŠ¡åœ°å€ | 0.0.0.0 |
| `API_PORT` | API æœåŠ¡ç«¯å£ | 8000 |
| `AI_CONFIDENCE_THRESHOLD` | è§¦å‘ AI çš„ç½®ä¿¡åº¦é˜ˆå€¼ | 0.6 |

## ğŸ”§ å¼€å‘

è¯¦ç»†å¼€å‘æ–‡æ¡£è¯·å‚é˜… [docs/DEVELOPER.md](docs/DEVELOPER.md)

æ¶æ„è®¾è®¡æ–‡æ¡£è¯·å‚é˜… [docs/V2_ARCHITECTURE.md](docs/V2_ARCHITECTURE.md)

```bash
# è¿è¡Œæµ‹è¯•
pytest3 tests/

# ä»£ç æ ¼å¼åŒ–
black .
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

åœ¨ 9,017 æ¡å¤šè¯­è¨€å…³é”®è¯æµ‹è¯•ä¸­ï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€» tokens | 29,745 |
| ä½ç½®ä¿¡åº¦è¯ (â‰¤0.5) | 10.4% |
| é«˜ç½®ä¿¡åº¦è¯ (â‰¥0.85) | 78.1% |
| å¤„ç†é€Ÿåº¦ | ~1000 æ¡/åˆ†é’Ÿ |

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ™ è‡´è°¢

- [jieba](https://github.com/fxsjy/jieba) - ä¸­æ–‡åˆ†è¯
- [SudachiPy](https://github.com/WorksApplications/SudachiPy) - æ—¥è¯­åˆ†è¯
- [Google Product Taxonomy](https://www.google.com/basepages/producttype/taxonomy.en-US.txt) - å•†å“åˆ†ç±»æ•°æ®
- [Anthropic Claude](https://www.anthropic.com/) - AI å¢å¼º
