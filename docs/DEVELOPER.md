# å¼€å‘è€…æ–‡æ¡£ - å¤šè¯­è¨€ç”µå•†å…³é”®è¯åˆ†è¯ä¸æ ‡æ³¨ç³»ç»Ÿ

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
3. [ç›®å½•ç»“æ„](#ç›®å½•ç»“æ„)
4. [æ ¸å¿ƒå¤„ç†æµç¨‹](#æ ¸å¿ƒå¤„ç†æµç¨‹)
5. [æ¨¡å—è¯¦è§£](#æ¨¡å—è¯¦è§£)
6. [è¯å…¸ç³»ç»Ÿ](#è¯å…¸ç³»ç»Ÿ)
7. [æ‰©å±•æŒ‡å—](#æ‰©å±•æŒ‡å—)
8. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## é¡¹ç›®æ¦‚è¿°

### è§£å†³çš„é—®é¢˜

ç”µå•†å…³é”®è¯ï¼ˆå¦‚å•†å“æ ‡é¢˜ã€æœç´¢è¯ï¼‰é€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- **å¤šè¯­è¨€æ··åˆ**ï¼š`Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º 26.5cm` åŒæ—¶åŒ…å«è‹±è¯­ã€æ—¥è¯­ã€æ•°å­—
- **æ— æ˜ç¡®åˆ†éš”**ï¼š`thermoleggingsdamen` å¾·è¯­å¤åˆè¯æ²¡æœ‰ç©ºæ ¼
- **éœ€è¦è¯­ä¹‰æ ‡æ³¨**ï¼šéœ€è¦è¯†åˆ«å‡º `Nike=å“ç‰Œè¯`ã€`ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º=å•†å“è¯`

### æ ¸å¿ƒåŠŸèƒ½

1. **æ™ºèƒ½åˆ†è¯**ï¼šæ ¹æ®å­—ç¬¦ç±»å‹è‡ªåŠ¨é€‰æ‹©åˆ†è¯å™¨ï¼ˆä¸­æ–‡/æ—¥è¯­/æ¬§æ´²è¯­è¨€ï¼‰
2. **è¯­ä¹‰æ ‡æ³¨**ï¼šå°†æ¯ä¸ªè¯æ ‡æ³¨ä¸º å“ç‰Œè¯/å•†å“è¯/äººç¾¤è¯/åœºæ™¯è¯/é¢œè‰²è¯/å°ºå¯¸è¯/å–ç‚¹è¯/å±æ€§è¯
3. **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šç»™å‡ºæ¯ä¸ªæ ‡æ³¨çš„å¯ä¿¡ç¨‹åº¦
4. **AI å¢å¼º**ï¼šå¯¹ä½ç½®ä¿¡åº¦è¯è°ƒç”¨ Claude API è¡¥å……æ ‡æ³¨

### æŠ€æœ¯æ ˆ

- **Python 3.9+**
- **jieba**ï¼šä¸­æ–‡åˆ†è¯
- **sudachipy**ï¼šæ—¥è¯­åˆ†è¯
- **FastAPI**ï¼šAPI æœåŠ¡
- **Claude API**ï¼šAI å¢å¼ºæ ‡æ³¨

---

## ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         è¾“å…¥å…³é”®è¯                                â”‚
â”‚              "Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º ãƒ¡ãƒ³ã‚º 26.5cm"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      1. é¢„å¤„ç† (Preprocessor)                    â”‚
â”‚                   - ç»Ÿä¸€ç¼–ç ã€æ¸…ç†ç‰¹æ®Šå­—ç¬¦                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  2. å›ºå®šçŸ­è¯­æå– (SpanExtractor)                  â”‚
â”‚              - æå–å“ç‰Œè¯ã€å·²çŸ¥çŸ­è¯­ï¼Œæ ‡è®°ä¸º"å·²é”å®š"                   â”‚
â”‚              - "Nike" â†’ [å“ç‰Œè¯, 0.95]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  3. è„šæœ¬åˆ†æ®µ (ScriptSegmenter)                    â”‚
â”‚              - æŒ‰å­—ç¬¦ç±»å‹åˆ‡åˆ†ï¼šLatin / Kana / CJK / Number         â”‚
â”‚              - "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º ãƒ¡ãƒ³ã‚º" â†’ [KANAæ®µ]                â”‚
â”‚              - "26.5cm" â†’ [Latin+Numberæ®µ]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    4. åˆ†æ®µåˆ†è¯ (Tokenizers)                       â”‚
â”‚              - KANAæ®µ â†’ JapaneseTokenizer (Sudachi)              â”‚
â”‚              - CJKæ®µ â†’ ChineseTokenizer (jieba)                  â”‚
â”‚              - Latinæ®µ â†’ EuropeanTokenizer (ç©ºæ ¼åˆ†è¯)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 5. æ—¥è¯­å¤åˆè¯åˆå¹¶ (JapaneseCompoundMerger)         â”‚
â”‚              - "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°" + "ã‚·ãƒ¥ãƒ¼ã‚º" â†’ "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º"       â”‚
â”‚              - åªåˆå¹¶è¯å…¸ä¸­å­˜åœ¨çš„å¤åˆè¯                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  6. çŸ­è¯­åˆå¹¶ (PhraseMerger)                       â”‚
â”‚              - "long" + "sleeve" â†’ "long sleeve"                 â”‚
â”‚              - æ¬§æ´²è¯­è¨€å›ºå®šæ­é…åˆå¹¶                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  7. æ ‡ç­¾æ ‡æ³¨ (EnhancedTagger)                     â”‚
â”‚              - å¤šå±‚ç­–ç•¥ï¼šè¯å…¸ â†’ è§„åˆ™ â†’ å¯å‘å¼ â†’ é»˜è®¤                 â”‚
â”‚              - è¥¿ç­ç‰™è¯­è¯å½¢å½’ä¸€åŒ–                                   â”‚
â”‚              - ä¸Šä¸‹æ–‡è°ƒæ•´                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  8. AI å¢å¼º (å¯é€‰) (AIEnhancer)                   â”‚
â”‚              - å¯¹ç½®ä¿¡åº¦ â‰¤ 0.6 çš„è¯è°ƒç”¨ Claude API                  â”‚
â”‚              - ç»“æœè¿›å…¥å€™é€‰æ± ï¼Œäººå·¥ç¡®è®¤åå†™å…¥è¯å…¸                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           è¾“å‡ºç»“æœ                                â”‚
â”‚  [                                                               â”‚
â”‚    {"token": "Nike", "tag": "å“ç‰Œè¯", "confidence": 0.95},        â”‚
â”‚    {"token": "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º", "tag": "å•†å“è¯", "confidence": 0.9},â”‚
â”‚    {"token": "ãƒ¡ãƒ³ã‚º", "tag": "äººç¾¤è¯", "confidence": 0.9},         â”‚
â”‚    {"token": "26.5cm", "tag": "å°ºå¯¸è¯", "confidence": 0.95}        â”‚
â”‚  ]                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç›®å½•ç»“æ„

```
keyword-tokenizer/
â”‚
â”œâ”€â”€ api/                          # API æœåŠ¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # FastAPI åº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ models/                   # è¯·æ±‚/å“åº”æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ request.py
â”‚   â”‚   â””â”€â”€ response.py
â”‚   â””â”€â”€ routes/                   # API è·¯ç”±
â”‚       â”œâ”€â”€ tokenize.py           # åˆ†è¯æ¥å£
â”‚       â””â”€â”€ dictionary.py         # è¯å…¸ç®¡ç†æ¥å£
â”‚
â”œâ”€â”€ config/                       # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py               # é…ç½®ç±»ï¼ˆè¯»å– .envï¼‰
â”‚
â”œâ”€â”€ core/                         # æ ¸å¿ƒå¤„ç†æ¨¡å— â­
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ enhanced_pipeline.py      # ä¸»å¤„ç†æµæ°´çº¿ï¼ˆå…¥å£ï¼‰
â”‚   â”œâ”€â”€ enhanced_tagger.py        # å¢å¼ºç‰ˆæ ‡ç­¾æ ‡æ³¨å™¨
â”‚   â”œâ”€â”€ preprocessor.py           # æ–‡æœ¬é¢„å¤„ç†
â”‚   â”œâ”€â”€ script_segmenter.py       # è„šæœ¬åˆ†æ®µå™¨
â”‚   â”œâ”€â”€ span_extractor.py         # å›ºå®šçŸ­è¯­æå–å™¨
â”‚   â”œâ”€â”€ phrase_merger.py          # æ¬§æ´²è¯­è¨€çŸ­è¯­åˆå¹¶
â”‚   â”œâ”€â”€ japanese_compound_merger.py  # æ—¥è¯­å¤åˆè¯åˆå¹¶
â”‚   â”œâ”€â”€ spanish_normalizer.py     # è¥¿ç­ç‰™è¯­è¯å½¢å½’ä¸€åŒ–
â”‚   â”œâ”€â”€ language_detector.py      # è¯­è¨€æ£€æµ‹
â”‚   â”œâ”€â”€ tagger.py                 # åŸºç¡€æ ‡ç­¾æ ‡æ³¨å™¨
â”‚   â”œâ”€â”€ pipeline.py               # åŸºç¡€æµæ°´çº¿ï¼ˆæ—§ç‰ˆï¼‰
â”‚   â””â”€â”€ tokenizers/               # åˆ†è¯å™¨
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py               # åŸºç±»
â”‚       â”œâ”€â”€ chinese.py            # ä¸­æ–‡åˆ†è¯ï¼ˆjiebaï¼‰
â”‚       â”œâ”€â”€ japanese.py           # æ—¥è¯­åˆ†è¯ï¼ˆsudachiï¼‰
â”‚       â””â”€â”€ european.py           # æ¬§æ´²è¯­è¨€åˆ†è¯
â”‚
â”œâ”€â”€ services/                     # æœåŠ¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dictionary_manager.py     # è¯å…¸ç®¡ç†å™¨
â”‚   â”œâ”€â”€ ai_enhancer.py            # AI å¢å¼ºæœåŠ¡ï¼ˆåŸºç¡€ç‰ˆï¼‰
â”‚   â”œâ”€â”€ ai_enhancer_v2.py         # AI å¢å¼ºæœåŠ¡ï¼ˆæ‰¹é‡ç‰ˆï¼‰
â”‚   â””â”€â”€ candidate_pool.py         # AI ç»“æœå€™é€‰æ± 
â”‚
â”œâ”€â”€ dictionaries/                 # è¯å…¸æ•°æ® ğŸ“š
â”‚   â”œâ”€â”€ products.json             # å•†å“è¯å…¸
â”‚   â”œâ”€â”€ brands.json               # å“ç‰Œè¯å…¸
â”‚   â”œâ”€â”€ brands/                   # å“ç‰Œå­è¯å…¸
â”‚   â”‚   â”œâ”€â”€ global.json
â”‚   â”‚   â”œâ”€â”€ zh.json
â”‚   â”‚   â””â”€â”€ ja.json
â”‚   â”œâ”€â”€ audiences.json            # äººç¾¤è¯å…¸
â”‚   â”œâ”€â”€ scenarios.json            # åœºæ™¯è¯å…¸
â”‚   â”œâ”€â”€ colors.json               # é¢œè‰²è¯å…¸
â”‚   â”œâ”€â”€ features.json             # å–ç‚¹è¯å…¸
â”‚   â”œâ”€â”€ attributes.json           # å±æ€§è¯å…¸
â”‚   â””â”€â”€ ja.json                   # æ—¥è¯­ä¸“ç”¨è¯å…¸
â”‚
â”œâ”€â”€ dict_expansion/               # è¯å…¸æ‰©å……æ¨¡å— ğŸ“š
â”‚   â”œâ”€â”€ apply_expansion.py        # æ‰©å……è„šæœ¬ï¼ˆè¯»å– JSON å¯¼å…¥è¯å…¸ï¼‰
â”‚   â”œâ”€â”€ english.json              # è‹±è¯­æ‰©å……è¯å…¸
â”‚   â”œâ”€â”€ french.json               # æ³•è¯­æ‰©å……è¯å…¸
â”‚   â”œâ”€â”€ german.json               # å¾·è¯­æ‰©å……è¯å…¸
â”‚   â”œâ”€â”€ japanese.json             # æ—¥è¯­æ‰©å……è¯å…¸
â”‚   â””â”€â”€ spanish.json              # è¥¿ç­ç‰™è¯­æ‰©å……è¯å…¸
â”‚
â”œâ”€â”€ scripts/                      # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ batch_test.py             # æ‰¹é‡æµ‹è¯•ï¼ˆåŸºç¡€ç‰ˆï¼‰
â”‚   â”œâ”€â”€ batch_test_v2.py          # æ‰¹é‡æµ‹è¯•ï¼ˆAI ä¼˜åŒ–ç‰ˆï¼‰
â”‚   â”œâ”€â”€ safe_dict_expand.py       # å®‰å…¨è¯å…¸æ‰©å……ï¼ˆæ—¥è¯­å¤åˆè¯ç­‰ï¼‰
â”‚   â”œâ”€â”€ import_ai_tags.py         # å¯¼å…¥ AI æ ‡æ³¨ç»“æœåˆ°è¯å…¸
â”‚   â””â”€â”€ security_check.py         # GitHub å¼€æºå®‰å…¨æ£€æŸ¥
â”‚
â”œâ”€â”€ tests/                        # æµ‹è¯•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core.py
â”‚   â””â”€â”€ test_tokenizer.py
â”‚
â”œâ”€â”€ docs/                         # æ–‡æ¡£
â”‚   â”œâ”€â”€ DEVELOPER.md              # å¼€å‘è€…æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”‚   â””â”€â”€ V2_ARCHITECTURE.md        # æ¶æ„è®¾è®¡æ–‡æ¡£
â”‚
â”œâ”€â”€ .env.example                  # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ .gitignore                    # Git å¿½ç•¥é…ç½®
â”œâ”€â”€ requirements.txt              # Python ä¾èµ–
â”œâ”€â”€ run.py                        # å¯åŠ¨è„šæœ¬
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

---

## æ ¸å¿ƒå¤„ç†æµç¨‹

### å…¥å£æ–‡ä»¶ï¼š`core/enhanced_pipeline.py`

```python
class EnhancedPipeline:
    async def process(self, keyword: str, language: str = None) -> Dict:
        # 1. é¢„å¤„ç†
        cleaned, _ = self.preprocessor.process(keyword)
        
        # 2. å›ºå®šçŸ­è¯­æå–ï¼ˆå“ç‰Œè¯ç­‰ï¼‰
        spans, locked_ranges = self.span_extractor.extract(cleaned)
        
        # 3. è„šæœ¬åˆ†æ®µ
        segments = self.segmenter.segment(cleaned)
        
        # 4. å¯¹æ¯æ®µè¿›è¡Œåˆ†è¯
        for segment in segments:
            tokenizer = self.get_tokenizer(segment.script)
            tokens = tokenizer.tokenize(segment.text)
        
        # 5. çŸ­è¯­åˆå¹¶ï¼ˆæ¬§æ´²è¯­è¨€ï¼‰
        merged_tokens = self.phrase_merger.merge(tokens)
        
        # 6. æ ‡ç­¾æ ‡æ³¨
        results = self.tagger.tag(tokens, language=language)
        
        # 7. AI å¢å¼ºï¼ˆå¯é€‰ï¼‰
        if self.ai_enhancer:
            results = await self._apply_ai_enhancement(results)
        
        return self._format_output(results)
```

---

## æ¨¡å—è¯¦è§£

### 1. é¢„å¤„ç†å™¨ (`core/preprocessor.py`)

**åŠŸèƒ½**ï¼šæ¸…ç†è¾“å…¥æ–‡æœ¬

```python
class Preprocessor:
    def process(self, text: str) -> Tuple[str, Dict]:
        # - ç»Ÿä¸€ Unicode ç¼–ç ï¼ˆNFKCï¼‰
        # - å…¨è§’è½¬åŠè§’
        # - æ¸…ç†å¤šä½™ç©ºæ ¼
        # - è®°å½•å¤„ç†è¿‡ç¨‹
        return cleaned_text, record
```

### 2. è„šæœ¬åˆ†æ®µå™¨ (`core/script_segmenter.py`)

**åŠŸèƒ½**ï¼šæŒ‰å­—ç¬¦ç±»å‹å°†æ··åˆè¯­è¨€æ–‡æœ¬åˆ‡åˆ†

```python
class ScriptSegmenter:
    def segment(self, text: str) -> List[Segment]:
        # è¾“å…¥: "Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° 26.5cm"
        # è¾“å‡º: [
        #   Segment("Nike", LATIN),
        #   Segment("ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°", KANA),
        #   Segment("26.5cm", LATIN)
        # ]
```

**æ”¯æŒçš„è„šæœ¬ç±»å‹**ï¼š
- `CJK`ï¼šä¸­æ–‡æ±‰å­—
- `KANA`ï¼šæ—¥è¯­å‡å
- `HANGUL`ï¼šéŸ©è¯­
- `LATIN`ï¼šæ‹‰ä¸å­—æ¯
- `NUMBER`ï¼šæ•°å­—

### 3. åˆ†è¯å™¨ (`core/tokenizers/`)

#### ä¸­æ–‡åˆ†è¯å™¨ (`chinese.py`)
```python
class ChineseTokenizer:
    def tokenize(self, text: str) -> List[Token]:
        # ä½¿ç”¨ jieba åˆ†è¯
        # æ”¯æŒåŠ¨æ€æ·»åŠ è¯ï¼ˆå“ç‰Œè¯ç­‰ï¼‰
```

#### æ—¥è¯­åˆ†è¯å™¨ (`japanese.py`)
```python
class JapaneseTokenizer:
    def tokenize(self, text: str) -> List[Token]:
        # ä½¿ç”¨ Sudachi (Mode C) åˆ†è¯
        # Mode C ä¿ç•™è¾ƒé•¿çš„å¤åˆè¯
```

#### æ¬§æ´²è¯­è¨€åˆ†è¯å™¨ (`european.py`)
```python
class EuropeanTokenizer:
    def tokenize(self, text: str) -> List[Token]:
        # åŸºäºç©ºæ ¼å’Œæ ‡ç‚¹åˆ†è¯
        # å¤„ç†å¾·è¯­å¤åˆè¯ï¼ˆ-åˆ†éš”ï¼‰
```

### 4. æ—¥è¯­å¤åˆè¯åˆå¹¶å™¨ (`core/japanese_compound_merger.py`)

**åŠŸèƒ½**ï¼šè§£å†³æ—¥è¯­è¿‡åº¦åˆ†è¯é—®é¢˜

```python
class JapaneseCompoundMerger:
    def merge(self, tokens: List[str]) -> List[str]:
        # è¾“å…¥: ["ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°", "ã‚·ãƒ¥ãƒ¼ã‚º"]
        # è¾“å‡º: ["ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º"]  # ä»…å½“è¯å…¸ä¸­å­˜åœ¨æ—¶
        
        # ç­–ç•¥ï¼š
        # 1. é¢„å®šä¹‰å¤åˆè¯è¯å…¸åŒ¹é…
        # 2. è¯å°¾è§„åˆ™åˆå¹¶ï¼ˆå·»+ã â†’ å·»ãï¼‰
        # 3. ç‰‡å‡åå•†å“è¯åˆå¹¶ï¼ˆéœ€è¯å…¸éªŒè¯ï¼‰
```

**å…³é”®è®¾è®¡**ï¼šåªåˆå¹¶è¯å…¸ä¸­å­˜åœ¨çš„è¯ï¼Œé¿å…ç”Ÿæˆæ— æ•ˆå¤åˆè¯

### 5. è¥¿ç­ç‰™è¯­å½’ä¸€åŒ–å™¨ (`core/spanish_normalizer.py`)

**åŠŸèƒ½**ï¼šå¤„ç†è¥¿ç­ç‰™è¯­å¤æ•°å’Œæ€§åˆ«å˜åŒ–

```python
class SpanishNormalizer:
    def normalize(self, word: str) -> NormalizedWord:
        # è¾“å…¥: "inalÃ¡mbricas"
        # è¾“å‡º: "inalÃ¡mbrico"
        
        # è§„åˆ™ï¼š
        # 1. å¤æ•°è¿˜åŸï¼š-s, -es â†’ å•æ•°
        # 2. æ€§åˆ«å½’ä¸€ï¼š-a â†’ -oï¼ˆéªŒè¯åï¼‰
```

### 6. çŸ­è¯­åˆå¹¶å™¨ (`core/phrase_merger.py`)

**åŠŸèƒ½**ï¼šåˆå¹¶æ¬§æ´²è¯­è¨€å›ºå®šæ­é…

```python
class PhraseMerger:
    def merge(self, tokens: List[str]) -> List[MergedToken]:
        # è¾“å…¥: ["long", "sleeve", "shirt"]
        # è¾“å‡º: ["long sleeve", "shirt"]
        
        # é¢„å®šä¹‰æ­é…ï¼š
        # - "long sleeve", "short sleeve"
        # - "high waist", "low waist"
        # - "quick dry", "water resistant"
```

### 7. å¢å¼ºç‰ˆæ ‡ç­¾æ ‡æ³¨å™¨ (`core/enhanced_tagger.py`)

**åŠŸèƒ½**ï¼šå¤šå±‚ç­–ç•¥æ ‡æ³¨ + ç½®ä¿¡åº¦è¯„ä¼°

```python
class EnhancedTagger:
    def tag(self, tokens: List[str], language: str = None) -> List[TagResult]:
        # æ ‡æ³¨ç­–ç•¥ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
        # 1. è¯å…¸åŒ¹é…ï¼ˆconfidence: 0.9-0.95ï¼‰
        # 2. æ­£åˆ™æ¨¡å¼ï¼ˆé¢œè‰²è¯ã€å°ºå¯¸è¯ï¼‰
        # 3. è§„åˆ™æ¨æ–­ï¼ˆå…³é”®å­—åˆ—è¡¨ï¼‰
        # 4. å¯å‘å¼æ¨æ–­ï¼ˆè¯ç¼€ã€ä½ç½®ï¼‰
        # 5. é»˜è®¤æ ‡ç­¾ï¼ˆconfidence: 0.5ï¼‰
        
        # ç‰¹æ®Šå¤„ç†ï¼š
        # - æ—¥è¯­å¤åˆè¯åˆå¹¶
        # - è¥¿ç­ç‰™è¯­å½’ä¸€åŒ–åŒ¹é…
        # - ä¸Šä¸‹æ–‡è°ƒæ•´
```

**æ ‡ç­¾ç±»å‹**ï¼š
| æ ‡ç­¾ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| å“ç‰Œè¯ | å“ç‰Œåç§° | Nike, Sony, ãƒŠã‚¤ã‚­ |
| å•†å“è¯ | å•†å“å“ç±» | leggings, ã‚·ãƒ¥ãƒ¼ã‚º, èƒŒåŒ… |
| äººç¾¤è¯ | ç›®æ ‡äººç¾¤ | damen, ãƒ¡ãƒ³ã‚º, kids |
| åœºæ™¯è¯ | ä½¿ç”¨åœºæ™¯ | running, ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ |
| é¢œè‰²è¯ | é¢œè‰² | schwarz, é»’, blue |
| å°ºå¯¸è¯ | å°ºå¯¸è§„æ ¼ | 26.5cm, XL, 32GB |
| å–ç‚¹è¯ | äº§å“ç‰¹æ€§ | waterproof, è»½é‡ |
| å±æ€§è¯ | å…¶ä»–å±æ€§ | with, fÃ¼r, long |

### 8. AI å¢å¼ºæœåŠ¡ (`services/ai_enhancer_v2.py`)

**åŠŸèƒ½**ï¼šå¯¹ä½ç½®ä¿¡åº¦è¯è°ƒç”¨ Claude API è¡¥å……æ ‡æ³¨

```python
class AIEnhancer:
    async def process_batch(self, words: List[str], context: str) -> Dict:
        # æ„é€  Promptï¼Œè°ƒç”¨ Claude API
        # è¿”å›æ¯ä¸ªè¯çš„æ ‡ç­¾å’Œç½®ä¿¡åº¦
        
        # è¾“å…¥: ["pilou", "gefÃ¼ttert"]
        # è¾“å‡º: {
        #   "pilou": {"tag": "å±æ€§è¯", "confidence": 0.85},
        #   "gefÃ¼ttert": {"tag": "å–ç‚¹è¯", "confidence": 0.9}
        # }
```

---

## è¯å…¸æ‰©å……æ¨¡å— (`dict_expansion/`)

### è®¾è®¡ç†å¿µ

å°†è¯å…¸æ‰©å……ä¸ä¸»ä»£ç åˆ†ç¦»ï¼Œä¾¿äºï¼š
- æŒ‰è¯­è¨€ç‹¬ç«‹ç»´æŠ¤
- ç‰ˆæœ¬æ§åˆ¶å‹å¥½ï¼ˆJSON æ–‡ä»¶æ˜“äº diffï¼‰
- æ”¯æŒæ‰¹é‡å®¡æ ¸åå†å¯¼å…¥

### æ‰©å……æ–‡ä»¶æ ¼å¼

```json
{
  "language": "german",
  "description": "å¾·è¯­è¯å…¸æ‰©å…… - åŸºäºæ‰¹é‡æµ‹è¯•ä½ç½®ä¿¡åº¦è¯æ±‡åˆ†æ",
  "stopwords": ["mit", "fÃ¼r", "und", "der", "die"],
  "entries": [
    {"word": "radlerhose", "tag": "å•†å“è¯", "confidence": 0.95, "note": "éª‘è¡Œè£¤"},
    {"word": "baumwolle", "tag": "å±æ€§è¯", "confidence": 0.9, "note": "æ£‰"}
  ]
}
```

**å­—æ®µè¯´æ˜**ï¼š
- `language`ï¼šè¯­è¨€æ ‡è¯†
- `stopwords`ï¼šè™šè¯åˆ—è¡¨ï¼ˆå¯¼å…¥æ—¶è‡ªåŠ¨è·³è¿‡ï¼‰
- `entries`ï¼šè¯æ¡åˆ—è¡¨
  - `word`ï¼šè¯æ±‡
  - `tag`ï¼šæ ‡ç­¾ç±»å‹
  - `confidence`ï¼šç½®ä¿¡åº¦
  - `note`ï¼šä¸­æ–‡æ³¨é‡Šï¼ˆä¾¿äºç†è§£ï¼‰

### ä½¿ç”¨æ–¹æ³•

```bash
# é¢„è§ˆï¼ˆä¸å®é™…ä¿®æ”¹ï¼‰
python3 dict_expansion/apply_expansion.py --dry-run

# å®é™…å¯¼å…¥
python3 dict_expansion/apply_expansion.py
```

### å·¥ä½œæµç¨‹

1. è¿è¡Œæ‰¹é‡æµ‹è¯•ï¼Œå‘ç°ä½ç½®ä¿¡åº¦è¯
2. åˆ†æåæ‰‹åŠ¨æ·»åŠ åˆ°å¯¹åº”è¯­è¨€çš„ JSON æ–‡ä»¶
3. è¿è¡Œ `apply_expansion.py` å¯¼å…¥è¯å…¸
4. é‡æ–°æµ‹è¯•éªŒè¯æ•ˆæœ

---

## è¯å…¸ç³»ç»Ÿ

### è¯å…¸æ ¼å¼

```json
{
  "name": "å•†å“è¯å…¸",
  "description": "å•†å“å“ç±»åç§°ï¼ˆå¤šè¯­è¨€ï¼‰",
  "entries": [
    {"word": "leggings", "confidence": 0.95},
    {"word": "ã‚·ãƒ¥ãƒ¼ã‚º", "confidence": 0.95},
    {"word": "èƒŒåŒ…", "confidence": 1.0}
  ]
}
```

### è¯å…¸ç®¡ç†å™¨ (`services/dictionary_manager.py`)

```python
class DictionaryManager:
    def load_all(self):
        # åŠ è½½æ‰€æœ‰è¯å…¸æ–‡ä»¶
        # æ„å»ºè¯ç´¢å¼•ï¼ˆå¿«é€ŸæŸ¥æ‰¾ï¼‰
    
    def contains(self, dict_name: str, word: str) -> bool:
        # æ£€æŸ¥è¯æ˜¯å¦åœ¨è¯å…¸ä¸­
    
    def add_word(self, dict_name: str, word: str, confidence: float):
        # æ·»åŠ æ–°è¯åˆ°è¯å…¸
```

---

## æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°è¯­è¨€æ”¯æŒ

1. åœ¨ `core/tokenizers/` åˆ›å»ºæ–°åˆ†è¯å™¨
2. åœ¨ `script_segmenter.py` æ·»åŠ å­—ç¬¦ç±»å‹è¯†åˆ«
3. åœ¨ `enhanced_tagger.py` æ·»åŠ è¯­è¨€ç‰¹å®šè§„åˆ™
4. åœ¨ `dictionaries/` æ·»åŠ è¯­è¨€è¯å…¸

### æ·»åŠ æ–°æ ‡ç­¾ç±»å‹

1. åœ¨ `enhanced_tagger.py` çš„ `TagType` æšä¸¾æ·»åŠ 
2. åœ¨ `dictionaries/` åˆ›å»ºå¯¹åº”è¯å…¸
3. åœ¨ `_match_dictionary()` æ·»åŠ æ˜ å°„

### æ·»åŠ æ–°è¯å…¸

```bash
# 1. åˆ›å»ºè¯å…¸æ–‡ä»¶
echo '{
  "name": "æ–°è¯å…¸",
  "description": "è¯´æ˜",
  "entries": []
}' > dictionaries/new_dict.json

# 2. åœ¨ dictionary_manager.py æ³¨å†Œ
```

---

## æ€§èƒ½ä¼˜åŒ–

### å½“å‰ä¼˜åŒ–

1. **è¯å…¸ç´¢å¼•**ï¼šä½¿ç”¨ dict å“ˆå¸Œè¡¨å¿«é€ŸæŸ¥æ‰¾
2. **å»¶è¿ŸåŠ è½½**ï¼šåˆ†è¯å™¨æŒ‰éœ€åˆå§‹åŒ–
3. **æ‰¹é‡å¤„ç†**ï¼šAI å¢å¼ºæ”¯æŒæ‰¹é‡è°ƒç”¨

### ä¼˜åŒ–å»ºè®®

1. **ç¼“å­˜**ï¼šå¯¹é«˜é¢‘è¯æ·»åŠ  LRU ç¼“å­˜
2. **å¹¶è¡Œ**ï¼šä½¿ç”¨ asyncio å¹¶è¡Œå¤„ç†å¤šä¸ªå…³é”®è¯
3. **é¢„ç¼–è¯‘**ï¼šæ­£åˆ™è¡¨è¾¾å¼é¢„ç¼–è¯‘

---

## è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹åˆ†è¯è¿‡ç¨‹

```python
from core.script_segmenter import ScriptSegmenter

segmenter = ScriptSegmenter()
segments = segmenter.segment("Nike ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° 26.5cm")
for seg in segments:
    print(f"[{seg.script.value}] {seg.text}")
```

### æŸ¥çœ‹æ ‡æ³¨è¯¦æƒ…

```python
# åœ¨ EnhancedTagger.tag() ä¸­æŸ¥çœ‹ all_candidates
for result in results:
    print(f"{result.token}: {result.primary_tag} ({result.confidence})")
    for cand in result.all_candidates:
        print(f"  - {cand.tag}: {cand.confidence} ({cand.method})")
```

---

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆæŸä¸ªè¯æ ‡æ³¨é”™è¯¯ï¼Ÿ

1. æ£€æŸ¥è¯å…¸æ˜¯å¦åŒ…å«è¯¥è¯
2. æ£€æŸ¥æ˜¯å¦æœ‰è§„åˆ™å†²çª
3. æŸ¥çœ‹ `all_candidates` äº†è§£æ ‡æ³¨è¿‡ç¨‹

### Q: å¦‚ä½•æé«˜æ ‡æ³¨å‡†ç¡®ç‡ï¼Ÿ

1. æ‰©å……è¯å…¸ï¼ˆæœ€ç›´æ¥ï¼‰
2. æ·»åŠ è¯­è¨€ç‰¹å®šè§„åˆ™
3. ä½¿ç”¨ AI å¢å¼º

### Q: å¦‚ä½•å¤„ç†æ–°çš„å¤åˆè¯ï¼Ÿ

1. æ—¥è¯­ï¼šæ·»åŠ åˆ° `products.json`ï¼Œåˆå¹¶å™¨ä¼šè‡ªåŠ¨è¯†åˆ«
2. æ¬§æ´²è¯­è¨€ï¼šæ·»åŠ åˆ° `phrase_merger.py` çš„é¢„å®šä¹‰æ­é…

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0 | æœ€åæ›´æ–°: 2025-01*

---

## å·¥å…·è„šæœ¬è¯¦è§£ (`scripts/`)

### æ ¸å¿ƒè„šæœ¬

| è„šæœ¬ | ç”¨é€” | ä½¿ç”¨é¢‘ç‡ |
|------|------|----------|
| `batch_test_v2.py` | æ‰¹é‡æµ‹è¯•å…³é”®è¯ï¼Œç”Ÿæˆç»“æœæŠ¥å‘Š |
| `import_ai_tags.py` | å°† AI æ ‡æ³¨ç»“æœå¯¼å…¥è¯å…¸ |
| `safe_dict_expand.py` | å®‰å…¨æ‰©å……è¯å…¸ï¼ˆæ—¥è¯­å¤åˆè¯ç­‰ï¼‰ |
| `security_check.py` | GitHub å¼€æºå‰å®‰å…¨æ£€æŸ¥ |

### è¾…åŠ©è„šæœ¬

| è„šæœ¬ | ç”¨é€” | è¯´æ˜ |
|------|------|------|
| `batch_test.py` | æ—§ç‰ˆæ‰¹é‡æµ‹è¯• | å·²è¢« v2 æ›¿ä»£ |
| `test_v2.py` | å•æ¡æµ‹è¯•è°ƒè¯• | å¼€å‘è°ƒè¯•ç”¨ |
| `test_api_model.py` | API æ¨¡å‹æµ‹è¯• | å¼€å‘è°ƒè¯•ç”¨ |
| `expand_dictionary.py` | è¯å…¸æ‰©å±• | åŠŸèƒ½ä¸ dict_expansion é‡å  |
| `expand_from_results.py` | ä»ç»“æœæ‰©å±•è¯å…¸ | åŠŸèƒ½ä¸ import_ai_tags é‡å  |

### ä½¿ç”¨ç¤ºä¾‹

```bash
# 1. æ‰¹é‡æµ‹è¯•ï¼ˆæœ€å¸¸ç”¨ï¼‰
python3 scripts/batch_test_v2.py keywords.csv -o results.json --no-ai

# 2. å¯¼å…¥ AI æ ‡æ³¨ç»“æœ
python3 scripts/import_ai_tags.py results_ai.json --dry-run  # é¢„è§ˆ
python3 scripts/import_ai_tags.py results_ai.json            # å®é™…å¯¼å…¥

# 3. å®‰å…¨æ‰©å……è¯å…¸
python3 scripts/safe_dict_expand.py --apply

# 4. å¼€æºå‰æ£€æŸ¥
python3 scripts/security_check.py
```
